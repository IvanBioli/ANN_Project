{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0a4a78",
   "metadata": {},
   "source": [
    "## 1. Import and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b25633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "from utils import *\n",
    "from q_learning import *\n",
    "from deep_q_learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890aa596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "save_stats = False\n",
    "save_figs = False\n",
    "train = False\n",
    "load = not train\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ce59f",
   "metadata": {},
   "source": [
    "## 2. Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a9ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TictactoeEnv()\n",
    "\n",
    "# Hyper-parameters\n",
    "alpha = 0.05    # Learning rate\n",
    "gamma = 0.99    # Discount factor\n",
    "epsilon_opt = 0.5   # Optimal player's epsilon\n",
    "num_episodes = 20000 # number of episodes\n",
    "num_avg = 10 # training runs\n",
    "test_freq = 250 # test frequency\n",
    "epsilon_min = 0.1 # minimum exploration rate for n^star\n",
    "epsilon_max = 0.8 # maximum exploration rate for n^star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c50a45",
   "metadata": {},
   "source": [
    "### 2.1 Learning from experts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ad0126",
   "metadata": {},
   "source": [
    "#### Question 1: Average reward with $\\epsilon = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3634d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Training, we average the results over 10 training runs\n",
    "epsilon_exploration = 0.1\n",
    "stats_dict_list = []\n",
    "if train:\n",
    "    for i in range(num_avg):\n",
    "        print('************** RUN', i+1, 'OF', num_avg, '**************')\n",
    "        stats_dict = {}\n",
    "        start = time.time()\n",
    "        Q, stats = q_learning(env, epsilon_exploration=epsilon_exploration, num_episodes=num_episodes, verbose=False, against_opt=True)\n",
    "        M_opt = measure_performance(QPlayer(Q=Q), OptimalPlayer(epsilon=0.))\n",
    "        M_rand = measure_performance(QPlayer(Q=Q), OptimalPlayer(epsilon=1.))\n",
    "        print(\"M_opt =\", M_opt)\n",
    "        print(\"M_rand =\", M_rand)\n",
    "        stats_dict.update({epsilon_exploration: (stats, M_opt, M_rand)})\n",
    "        stats_dict_list.append(stats_dict)\n",
    "        print('RUN', i+1, 'took', np.round(time.time()-start,decimals=1), 'seconds')\n",
    "    # Saving the results\n",
    "    if save_stats:\n",
    "        output_folder = os.path.join(os.getcwd(), 'results')\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        fname = output_folder + '/Q1.pkl'\n",
    "        with open(fname, 'wb') as handle:\n",
    "            pickle.dump(stats_dict_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load results from dictionary\n",
    "if load:\n",
    "    output_folder = os.path.join(os.getcwd(), 'results')\n",
    "    fname = output_folder + '/Q1.pkl'\n",
    "    with open(fname, 'rb') as handle:\n",
    "        stats_dict_list = pickle.load(handle)\n",
    "        \n",
    "# Plot of the average reward over num_avg training runs with 25th and 75th percentiles'        \n",
    "plot_stats(stats_dict_list, [epsilon_exploration], 'epsilon_exploration_Q1', '\\epsilon', save=save_figs, keys = ['rewards'], perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad2dcf",
   "metadata": {},
   "source": [
    "#### Questions 2 and 3: Average reward and performance measures for different values of $n^{\\star}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_freq = 250\n",
    "vec_n_star = np.hstack((np.array([1, 100, 500, 750]), np.round(np.logspace(3, np.log10(40000), 16))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_learning_params_list = []\n",
    "var_name = 'q_learning_n_star_experts'\n",
    "for n_star in vec_n_star:\n",
    "    params = {'env': env,\n",
    "              'epsilon_exploration_rule': return_lambda_explor(epsilon_min, epsilon_max, n_star),\n",
    "              'test_freq': test_freq, \n",
    "              'against_opt': True}\n",
    "    q_learning_params_list.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73c26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Training, performs num_avg complete training runs\n",
    "if train:\n",
    "    stats_dict_nstar = train_avg(var_name, vec_n_star, q_learning_params_list, num_avg=num_avg, save_stats=save_stats)\n",
    "\n",
    "# Load results from dictionary\n",
    "if load:\n",
    "    output_folder = os.path.join(os.getcwd(), 'results')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    fname = output_folder + '/Q2_Q3.pkl'\n",
    "    with open(fname, 'rb') as handle:\n",
    "        stats_dict_nstar_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f71af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot presented in the report\n",
    "plot_n_star = [1., 9146., 19127., 40000]\n",
    "plot_stats(stats_dict_nstar_list, plot_n_star, 'n_star', \"n^{\\star}\", save=save_figs, decaying_exploration=True, perc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c316af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot of all the experimented values\n",
    "plot_stats(stats_dict_nstar_list, vec_n_star, 'n_star', \"n^{\\star}\", save=save_figs, decaying_exploration=True, perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08353c3",
   "metadata": {},
   "source": [
    "#### Question 4: Good experts and bad experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e7852",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_star = 9146 # best value according to previous experiments\n",
    "M = 11\n",
    "vec_eps_opt = np.round(np.linspace(0, 1, M), decimals=2)\n",
    "var_name = 'epsilon_opt'\n",
    "q_learning_params_list = []\n",
    "for epsilon_opt in vec_eps_opt:\n",
    "    params = {'env': env,\n",
    "              'num_episodes': num_episodes,\n",
    "              'epsilon_exploration_rule': return_lambda_explor(epsilon_min, epsilon_max, best_n_star),\n",
    "              'epsilon_opt': epsilon_opt,\n",
    "              'against_opt': True}\n",
    "    q_learning_params_list.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a084f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Training, performs num_avg complete training runs\n",
    "if train:\n",
    "    stats_dict_eps_opt_list = train_avg(var_name, vec_eps_opt, q_learning_params_list, num_avg=num_avg, save_stats=save_stats)\n",
    "    \n",
    "# Load results from dictionary\n",
    "if load:\n",
    "    output_folder = os.path.join(os.getcwd(), 'results')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    fname = output_folder + '/Q4.pkl'\n",
    "    with open(fname, 'rb') as handle:\n",
    "        stats_dict_eps_opt_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot presented in the report\n",
    "plot_eps_opt = [0., 0.2, 0.5, 0.8, 1.]\n",
    "plot_stats(stats_dict_eps_opt_list, plot_eps_opt, \"epsilon_opt\", \"\\epsilon_{opt}\", save=save_figs, keys=['test_Mopt', 'test_Mrand'], perc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeaa4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot of all the experimented values\n",
    "plot_stats(stats_dict_eps_opt_list, vec_eps_opt, \"epsilon_opt\", \"\\epsilon_{opt}\", save=False, keys=['test_Mopt', 'test_Mrand'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c6407a",
   "metadata": {},
   "source": [
    "#### Question 5: Optimal values of $M_{\\text{opt}}$ and $M_{\\text{rand}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Setting hyperparams\n",
    "n_star = 9146 # best n_star\n",
    "epsilon_min = 0.1\n",
    "epsilon_max = 0.8\n",
    "epsilon_exploration_rule = return_lambda_explor(epsilon_min, epsilon_max, n_star)\n",
    "\n",
    "# Training, single sample run\n",
    "print(\"****************** SAMPLE RUN ****************\")\n",
    "Q, stats = q_learning(env, epsilon_exploration_rule = epsilon_exploration_rule, against_opt=True)\n",
    "\n",
    "# Print results\n",
    "M_opt = measure_performance(DeepQPlayer(model=model), OptimalPlayer(epsilon=0.))\n",
    "print(\"M_opt =\", M_opt)\n",
    "M_rand = measure_performance(DeepQPlayer(model=model), OptimalPlayer(epsilon=1.))\n",
    "print(\"M_rand =\", M_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a19b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************  AVERAGE STATS  *********************\n",
      "Median: M_opt =  0.0  M_rand =  0.85\n",
      "25th quantile: M_opt =  0.0  M_rand =  0.82\n",
      "75th quantile: M_opt =  0.0  M_rand =  0.89\n"
     ]
    }
   ],
   "source": [
    "# *************** RESULTS FOR THE SAME PARAMETERS FROM DICTIONARY *************\n",
    "output_folder = os.path.join(os.getcwd(), 'results')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "fname = output_folder + '/Q4.pkl'\n",
    "with open(fname, 'rb') as handle:\n",
    "    stats_dict = pickle.load(handle)\n",
    "    \n",
    "# Best_n_star\n",
    "stats_dict_best_n_star = [stats_dict[i][0.5] for i in range(10)]\n",
    "m_opt_vec = [stats_dict_best_n_star[i][1] for i in range(10)]\n",
    "m_rand_vec = [stats_dict_best_n_star[i][2] for i in range(10)]\n",
    "\n",
    "\n",
    "# Results\n",
    "print('*********************', ' AVERAGE STATS ', '*********************')\n",
    "print(\"Median: M_opt = \", np.round(np.median(m_opt_vec),decimals=2), \" M_rand = \", np.round(np.median(m_rand_vec),decimals=2))\n",
    "print(\"25th quantile: M_opt = \", np.round(np.percentile(m_opt_vec, q=25),decimals=2), \n",
    "      \" M_rand = \", np.round(np.percentile(m_rand_vec, q=25),decimals=2))\n",
    "print(\"75th quantile: M_opt = \", np.round(np.percentile(m_opt_vec, q=75),decimals=2),\n",
    "      \" M_rand = \", np.round(np.percentile(m_rand_vec, q=75),decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60a2e3",
   "metadata": {},
   "source": [
    "### 2.2 Learning by self-practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352755b8",
   "metadata": {},
   "source": [
    "#### Question 7: performance measures $M_{\\text{opt}}$ and $M_{\\text{rand}}$ for different exploration rates $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_vec = np.round(np.linspace(0, 0.9, 10), decimals=1)\n",
    "var_name = 'eps_self'\n",
    "q_learning_params_list = []\n",
    "for eps in eps_vec:\n",
    "    params = {'env': env,\n",
    "              'verbose': True,\n",
    "              'num_episodes': num_episodes,\n",
    "              'epsilon_exploration': eps,\n",
    "              'test_freq': test_freq,\n",
    "              'self_practice': True}\n",
    "    q_learning_params_list.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b827e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Training, performs num_avg complete training runs\n",
    "if train:\n",
    "    stats_dict_eps_self_list = train_avg(var_name, eps_vec, q_learning_params_list, num_avg=num_avg, save_stats=False)\n",
    "\n",
    "# Load results from dictionary\n",
    "if load:\n",
    "    output_folder = os.path.join(os.getcwd(), 'results')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    fname = output_folder + '/Q7.pkl'\n",
    "    with open(fname, 'rb') as handle:\n",
    "        stats_dict_eps_self_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c3f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot presented in the report\n",
    "eps_vec_plot = [0, 0.2, 0.5, 0.8]\n",
    "plot_stats(stats_dict_eps_self_list, eps_vec_plot, \"epsilon_self\", \"\\epsilon\", save=save_figs, perc=True, keys=['test_Mopt', 'test_Mrand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot of all the experimented values\n",
    "plot_stats(stats_dict_eps_self_list, eps_vec, \"epsilon_self\", \"\\epsilon\", save=False, keys=['test_Mopt', 'test_Mrand'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2bf9b2",
   "metadata": {},
   "source": [
    "#### Question 8: Performance measures  $M_{\\text{opt}}$ and $M_{\\text{rand}}$ for different values of $n^{\\star}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635400a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_min = 0.1\n",
    "epsilon_max = 0.8\n",
    "vec_n_star = np.hstack((np.array([1, 100, 500, 750]), np.round(np.logspace(3, np.log10(40000), 16))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd80807",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_learning_params_list = []\n",
    "var_name = 'q_learning_n_star_self'\n",
    "for n_star in vec_n_star:\n",
    "    params = {'env': env,\n",
    "              'num_episodes': num_episodes,\n",
    "              'epsilon_exploration_rule': return_lambda_explor(epsilon_min, epsilon_max, n_star),\n",
    "              'test_freq': test_freq,\n",
    "              'self_practice': True}\n",
    "    q_learning_params_list.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b3d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Training, performs num_avg complete training runs\n",
    "if train:\n",
    "    stats_dict_nstar = train_avg(var_name, vec_n_star, q_learning_params_list, num_avg=num_avg, save_stats=save_stats)\n",
    "\n",
    "# Load results from dictionary \n",
    "if load:\n",
    "    output_folder = os.path.join(os.getcwd(), 'results')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    fname = output_folder + '/Q8.pkl'\n",
    "    with open(fname, 'rb') as handle:\n",
    "        stats_dict_nstar_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot presented in the report\n",
    "plot_n_star = [1., 9146., 24460., 40000.]\n",
    "plot_stats(stats_dict_nstar_list, plot_n_star, 'n_star_self', \"n^{\\star}\", \n",
    "           decaying_exploration=True, save=save_figs, perc=True, keys=['test_Mopt', 'test_Mrand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0959a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot of all the experimented values\n",
    "plot_stats(stats_dict_nstar_list, vec_n_star, 'n_star_self', \"n^{\\star}\", save=False, keys=['test_Mopt', 'test_Mrand'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce8eef",
   "metadata": {},
   "source": [
    "#### Question 9: Optimal values of $M_{\\text{opt}}$ and $M_{\\text{rand}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaae520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Setting hyperparams\n",
    "n_star = 24460\n",
    "epsilon_exploration_rule = return_lambda_explor(epsilon_min, epsilon_max, n_star)\n",
    "\n",
    "\n",
    "# Training, single sample run\n",
    "print(\"************* SAMPLE RUN *************\")\n",
    "Q, stats = q_learning(env, epsilon_exploration_rule = epsilon_exploration_rule, self_practice=True)\n",
    "\n",
    "# Print results\n",
    "M_opt = measure_performance(DeepQPlayer(model=model), OptimalPlayer(epsilon=0.))\n",
    "print(\"M_opt =\", M_opt)\n",
    "M_rand = measure_performance(DeepQPlayer(model=model), OptimalPlayer(epsilon=1.))\n",
    "print(\"M_rand =\", M_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd91cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************  AVERAGE STATS  *********************\n",
      "Median: M_opt =  -0.07  M_rand =  0.87\n",
      "25th quantile: M_opt =  -0.19  M_rand =  0.86\n",
      "75th quantile: M_opt =  0.0  M_rand =  0.9\n"
     ]
    }
   ],
   "source": [
    "# *************** RESULTS FOR THE SAME PARAMETERS FROM DICTIONARY *************\n",
    "output_folder = os.path.join(os.getcwd(), 'results')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "fname = output_folder + '/Q8.pkl'\n",
    "with open(fname, 'rb') as handle:\n",
    "    stats_dict = pickle.load(handle)\n",
    "    \n",
    "# Best_n_star\n",
    "stats_dict_best_n_star = [stats_dict[i][24460.] for i in range(10)]\n",
    "m_opt_vec = [stats_dict_best_n_star[i][1] for i in range(10)]\n",
    "m_rand_vec = [stats_dict_best_n_star[i][2] for i in range(10)]\n",
    "\n",
    "\n",
    "# Results\n",
    "print('*********************', ' AVERAGE STATS ', '*********************')\n",
    "print(\"Median: M_opt = \", np.round(np.median(m_opt_vec),decimals=2), \" M_rand = \", np.round(np.median(m_rand_vec),decimals=2))\n",
    "print(\"25th quantile: M_opt = \", np.round(np.percentile(m_opt_vec, q=25),decimals=2), \n",
    "      \" M_rand = \", np.round(np.percentile(m_rand_vec, q=25),decimals=2))\n",
    "print(\"75th quantile: M_opt = \", np.round(np.percentile(m_opt_vec, q=75),decimals=2),\n",
    "      \" M_rand = \", np.round(np.percentile(m_rand_vec, q=75),decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a6a115",
   "metadata": {},
   "source": [
    "#### Question 10: Heatmaps of the Q-values in 3 significant states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ae273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Optimal params\n",
    "epsilon_min = 0.1\n",
    "epsilon_max = 0.8\n",
    "n_star = 24460\n",
    "epsilon_exploration_rule = return_lambda_explor(epsilon_min, epsilon_max, n_star)\n",
    "\n",
    "# Training\n",
    "Q, stats = q_learning(env, epsilon_exploration_rule=epsilon_exploration_rule, self_practice=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489fbc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States of interest\n",
    "win_chance = [1., 0., 0., -1., 1., 0., 0., -1., 0.]\n",
    "block_win = [1., 0., 1., 0., -1., 0., 0., 0., 0.]\n",
    "fork_chance = [1., -1., 1., -1., 0., 0., 0., 0., 0.]\n",
    "grids = [win_chance, block_win, fork_chance]\n",
    "\n",
    "\n",
    "grid_numpy = []\n",
    "for i in range(len(grids)):\n",
    "    grid_numpy.append(np.array(grids[i]).reshape(3,3))\n",
    "    \n",
    "# Plot heatmaps\n",
    "heatmaps_subplots(grid_numpy, Q, save=save_figs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86761e",
   "metadata": {},
   "source": [
    "## 3. Deep Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration paramaters for the whole setup\n",
    "env = TictactoeEnv()\n",
    "\n",
    "lr = 1e-4 # learning rate obtained by grid search\n",
    "num_episodes = 20000\n",
    "test_freq = 250\n",
    "num_avg = 4\n",
    "epsilon_min = 0.1\n",
    "epsilon_max = 0.8\n",
    "\n",
    "# Folder for results\n",
    "output_folder = os.path.join(os.getcwd(), 'results')\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a35e0",
   "metadata": {},
   "source": [
    "### 3.1 Learning from experts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158460b5",
   "metadata": {},
   "source": [
    "#### Question 11: Average reward and average loss during training for $\\epsilon = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Training, performs num_avg complete training runs without performance test\n",
    "epsilon_exploration = 0.1\n",
    "stats_dict_list = []\n",
    "if train:\n",
    "    for i in range(num_avg):\n",
    "        print('************** RUN', i+1, 'OF', num_avg, '**************')\n",
    "        stats_dict = {}\n",
    "        start = time.time()\n",
    "        model, stats = deep_q_learning(env, lr = lr, epsilon_exploration=epsilon_exploration, num_episodes=num_episodes, against_opt=True, verbose=True)\n",
    "        print('Only training time: ', time.time() - start)\n",
    "        M_opt = measure_performance(DeepQPlayer(model=model), OptimalPlayer(epsilon=0.))\n",
    "        M_rand = measure_performance(DeepQPlayer(model=model), OptimalPlayer(epsilon=1.))\n",
    "        print(\"M_opt =\", M_opt)\n",
    "        print(\"M_rand =\", M_rand)\n",
    "        stats_dict.update({epsilon_exploration: (stats, M_opt, M_rand)})\n",
    "        stats_dict_list.append(stats_dict)\n",
    "        print('RUN', i+1, 'took', np.round(time.time()-start,decimals=1), 'seconds')\n",
    "    if save_stats:\n",
    "        fname = output_folder + '/dqn_stats_dict_q11.pkl'\n",
    "        with open(fname, 'wb') as handle:\n",
    "            pickle.dump(stats_dict_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load results from dictionary\n",
    "if load:\n",
    "    fname = output_folder + '/Q11.pkl'\n",
    "    with open(fname, 'rb') as handle:\n",
    "            stats_dict_list = pickle.load(handle)\n",
    "\n",
    "# Plot of the average reward and average training loss over num_avg training runs with 25th and 75th percentiles'   \n",
    "plot_stats(stats_dict_list, [epsilon_exploration], 'epsilon_exploration_Q11', '\\epsilon', save=save_figs, keys = ['rewards', 'loss'], perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d2a7ba",
   "metadata": {},
   "source": [
    "#### Question 12: Same as Question 11, but no replay buffer and batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b60ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Training, performs num_avg complete training runs without performance test\n",
    "epsilon_exploration = 0.1\n",
    "stats_dict_list = []\n",
    "if train:\n",
    "    for i in range(num_avg):\n",
    "        print('************** RUN', i+1, 'OF', num_avg, '**************')\n",
    "        stats_dict = {}\n",
    "        start = time.time()\n",
    "        model, stats = deep_q_learning(env, epsilon_exploration=epsilon_exploration, num_episodes=num_episodes, against_opt=True, batch_size=1, max_memory_length=1)\n",
    "        M_opt = measure_performance(DeepQPlayer(model=model), OptimalPlayer(epsilon=0.))\n",
    "        M_rand = measure_performance(DeepQPlayer(model=model), OptimalPlayer(epsilon=1.))\n",
    "        print(\"M_opt =\", M_opt)\n",
    "        print(\"M_rand =\", M_rand)\n",
    "        stats_dict.update({epsilon_exploration: (stats, M_opt, M_rand)})\n",
    "        stats_dict_list.append(stats_dict)\n",
    "        print('RUN', i+1, 'took', np.round(time.time()-start,decimals=1), 'seconds')\n",
    "    if save_stats:\n",
    "        fname = output_folder + '/Q12.pkl'\n",
    "        with open(fname, 'wb') as handle:\n",
    "            pickle.dump(stats_dict_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load results from dictionary\n",
    "if load:\n",
    "    fname = output_folder + '/Q12.pkl'\n",
    "    with open(fname, 'rb') as handle:\n",
    "            stats_dict_list = pickle.load(handle)\n",
    "\n",
    "# Plot of the average reward and average training loss over num_avg training runs with 25th and 75th percentiles'              \n",
    "plot_stats(stats_dict_list, [epsilon_exploration], 'epsilon_exploration_Q12', '\\epsilon', save=save_figs, keys = ['rewards', 'loss'], perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9567db",
   "metadata": {},
   "source": [
    "#### Question 13: Performance measures $M_{\\text{opt}}$ and $M_{\\text{rand}}$ for different values of $n^{*}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61977197",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_n_star = np.hstack((np.array([1, 100, 1000]), np.round(np.logspace(np.log10(5000), np.log10(40000), 7))))\n",
    "var_name = 'deep_q_learning_n_star_experts'\n",
    "dqn_params_list = []\n",
    "for n_star in vec_n_star:\n",
    "    params = {'env': env,\n",
    "              'num_episodes': num_episodes,\n",
    "              'epsilon_exploration_rule': return_lambda_explor(epsilon_min, epsilon_max, n_star),\n",
    "              'test_freq': test_freq,\n",
    "              'against_opt': True}\n",
    "    dqn_params_list.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Training, performs num_avg complete training runs\n",
    "if train:\n",
    "    stats_dict_nstar = deep_train_avg(var_name, vec_n_star, dqn_params_list, num_avg=num_avg, save_stats=save_stats)\n",
    "\n",
    "# Load results from dictionary\n",
    "if load:\n",
    "    output_folder = os.path.join(os.getcwd(), 'results')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    fname = output_folder + '/Q13.pkl'\n",
    "    with open(fname, 'rb') as handle:\n",
    "        stats_dict_nstar_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1420951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot presented in the report\n",
    "plot_n_star = [1., 10000., 20000., 40000.]\n",
    "plot_stats(stats_dict_nstar_list, plot_n_star, 'dqn_n_star', \"n^{\\star}\", save=save_figs, perc=True, keys=['test_Mopt', 'test_Mrand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8378a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot of all the experimented values\n",
    "plot_stats(stats_dict_nstar_list, vec_n_star, 'dqn_n_star', \"n^{\\star}\", save=False, decaying_exploration=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6fcb6b",
   "metadata": {},
   "source": [
    "#### Question 14: Performance measures  $M_{\\text{opt}}$ and $M_{\\text{rand}}$ for different values of $\\epsilon_{\\text{opt}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_star = 20000 # best n_star according to the previous experiments\n",
    "M = 11\n",
    "vec_eps_opt = np.round(np.linspace(0, 1, M), decimals=2)\n",
    "deep_q_learning_params_list = []\n",
    "var_name = 'deep_q_learning_epsilon_opt_experts'\n",
    "for eps in vec_eps_opt:\n",
    "    params = {'env': env,\n",
    "              'num_episodes': num_episodes,\n",
    "              'epsilon_exploration_rule': return_lambda_explor(epsilon_min, epsilon_max, best_n_star),\n",
    "              'epsilon_opt': eps,\n",
    "              'test_freq': test_freq,\n",
    "              'against_opt': True}\n",
    "    deep_q_learning_params_list.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd429f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Training, performs num_avg complete training runs\n",
    "if train:\n",
    "    stats_dict_epsilon_opt_list_deep = deep_train_avg(var_name, vec_eps_opt, deep_q_learning_params_list, \n",
    "                                                      num_avg=num_avg, save_stats=save_stats)\n",
    "\n",
    "# Load results from dictionary\n",
    "if load:\n",
    "    output_folder = os.path.join(os.getcwd(), 'results')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    fname = output_folder + '/Q14.pkl'\n",
    "    with open(fname, 'rb') as handle:\n",
    "        stats_dict_eps_opt_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot presented in the report\n",
    "plot_epsilon_opt = [0.0, 0.2, 0.5, 0.7, 1.0]\n",
    "plot_stats(stats_dict_eps_opt_list, plot_epsilon_opt, 'dqn_epsilon_opt_experts', \"\\epsilon_{opt}\", save=save_figs, perc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot of all the experimented values\n",
    "plot_stats(stats_dict_eps_opt_list, vec_eps_opt, 'dqn_epsilon_opt_experts', \"\\epsilon_{opt}\", save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee1affb",
   "metadata": {},
   "source": [
    "#### Question 15: Optimal values of $M_{\\text{opt}}$ and $M_{\\text{rand}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0053c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*************** SAMPLE RUN *******************\")\n",
    "\n",
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Optimal params\n",
    "epsilon_min = 0.1\n",
    "epsilon_max = 0.8\n",
    "n_star = 20000\n",
    "epsilon_exploration_rule = return_lambda_explor(epsilon_min, epsilon_max, n_star)\n",
    "\n",
    "# Training, single run\n",
    "model, stats = deep_q_learning(env, epsilon_exploration_rule=epsilon_exploration_rule, against_opt=True)\n",
    "\n",
    "# Print results\n",
    "M_opt = measure_performance(DeepQPlayer(model=model), OptimalPlayer(epsilon=0.))\n",
    "print(\"M_opt = \", M_opt)\n",
    "M_rand = measure_performance(DeepQPlayer(model=model), OptimalPlayer(epsilon=1.))\n",
    "print(\"M_rand = \", M_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2c9411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************  AVERAGE STATS  *********************\n",
      "Median:\t M_opt =  0.0 \t M_rand =  0.94\n"
     ]
    }
   ],
   "source": [
    "# *************** RESULTS FOR THE SAME PARAMETERS FROM DICTIONARY *************\n",
    "output_folder = os.path.join(os.getcwd(), 'results')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "fname = output_folder + '/Q14.pkl'\n",
    "with open(fname, 'rb') as handle:\n",
    "    stats_dict = pickle.load(handle)\n",
    "    \n",
    "# Best_n_star\n",
    "stats_dict_best_n_star = [stats_dict[i][0.5] for i in range(4)]\n",
    "final_m_opt = [stats_dict_best_n_star[i][1] for i in range(4)]\n",
    "final_m_rand = [stats_dict_best_n_star[i][2] for i in range(4)]\n",
    "\n",
    "# Results\n",
    "print('*********************', ' AVERAGE STATS ', '*********************')\n",
    "print(\"Median:\\t M_opt = \", np.round(np.median(final_m_opt),decimals=2),\n",
    "      \"\\t M_rand = \", np.round(np.median(final_m_rand),decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceb228c",
   "metadata": {},
   "source": [
    "## 3.2 Learning by self-practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61df7f",
   "metadata": {},
   "source": [
    "#### Question 16: Performance measures $M_{\\text{opt}}$ and $M_{\\text{rand}}$ for different exploration rates $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad01629",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10\n",
    "vec_eps = np.linspace(0, 0.9, M)\n",
    "var_name = 'deep_q_learning_epsilon_self'\n",
    "dqn_params_list = []\n",
    "for eps in vec_eps:\n",
    "    params = {'env': env,\n",
    "          'num_episodes': num_episodes,\n",
    "          'epsilon_exploration': eps,\n",
    "          'verbose': True,\n",
    "          'test_freq': test_freq,\n",
    "          'self_practice': True}\n",
    "    dqn_params_list.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8676988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Training, performs num_avg complete training runs\n",
    "if train:\n",
    "    stats_dict_epsilon_self_list_deep = deep_train_avg(var_name, vec_eps, dqn_params_list, num_avg=num_avg, save_stats=save_stats)\n",
    "\n",
    "# Load results from dictionary\n",
    "if load:\n",
    "    output_folder = os.path.join(os.getcwd(), 'results')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    fname = output_folder + '/Q16.pkl'\n",
    "    with open(fname, 'rb') as handle:\n",
    "        stats_dict_epsilon_self_list_deep = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598120fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot presented in the report\n",
    "plot_eps = [0, 0.2, 0.5, 0.8]\n",
    "plot_stats(stats_dict_epsilon_self_list_deep, plot_eps, 'epsilon_dqn_self', \"\\epsilon\",\n",
    "           save=save_figs, perc=True, keys=['test_Mopt', 'test_Mrand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot of all the experimented values\n",
    "plot_stats(stats_dict_epsilon_self_list_deep, vec_eps, 'epsilon', \"\\epsilon\", save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f84700b",
   "metadata": {},
   "source": [
    "#### Question 17: Performance measures $M_{\\text{opt}}$ and $M_{\\text{rand}}$ for different values of $n^{\\star}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ac405",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_n_star = np.hstack((np.array([1, 100, 1000]), np.round(np.logspace(np.log10(5000), np.log10(40000), 7))))\n",
    "var_name = 'deep_q_learning_n_star_self'\n",
    "dqn_params_list = []\n",
    "for n_star in vec_n_star:\n",
    "    params = {'env': env,\n",
    "          'num_episodes': num_episodes,\n",
    "          'epsilon_exploration_rule': return_lambda_explor(epsilon_min, epsilon_max, n_star),\n",
    "          'verbose': True,\n",
    "          'test_freq': test_freq,\n",
    "          'self_practice': True}\n",
    "    dqn_params_list.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefbe3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Training, performs num_avg complete training runs\n",
    "if train:\n",
    "    stats_dict_nstar_self_list_deep = deep_train_avg(var_name, vec_n_star, dqn_params_list, \n",
    "                                                     num_avg=num_avg, save_stats=save_stats)\n",
    "\n",
    "# Load results from dictionary\n",
    "if load:\n",
    "    output_folder = os.path.join(os.getcwd(), 'results')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    fname = output_folder + '/Q17.pkl'\n",
    "    with open(fname, 'rb') as handle:\n",
    "        stats_dict_nstar_self_list_deep = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot presented in the report\n",
    "plot_n_star = [1., 10000., 20000., 40000.]\n",
    "plot_stats(stats_dict_nstar_self_list_deep, plot_n_star, 'n_star_dqn_self', \"n^{\\star}\", save=save_figs, decaying_exploration=True, perc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot of all the experimented values\n",
    "plot_stats(stats_dict_nstar_self_list_deep, vec_n_star, 'n_star', \"n^{\\star}\", save=False, decaying_exploration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e99cf",
   "metadata": {},
   "source": [
    "#### Question 18: Optimal values of $M_{\\text{opt}}$ and $M_{\\text{rand}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f27363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************** SAMPLE RUN ***********************\n",
    "\n",
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Parameters\n",
    "epsilon_min = 0.1\n",
    "epsilon_max = 0.8\n",
    "n_star = 10000\n",
    "epsilon_exploration_rule = return_lambda_explor(epsilon_min, epsilon_max, n_star)\n",
    "\n",
    "# Training, single run\n",
    "print(\"***************** SAMPLE RUN ***************\")\n",
    "\n",
    "model, stats = deep_q_learning(env, epsilon_exploration_rule=epsilon_exploration_rule, self_practice=True)\n",
    "\n",
    "# Print results\n",
    "M_opt = measure_performance(DeepQPlayer(model=model), OptimalPlayer(epsilon=0.))\n",
    "print(\"M_opt =\", M_opt)\n",
    "M_rand = measure_performance(DeepQPlayer(model=model), OptimalPlayer(epsilon=1.))\n",
    "print(\"M_rand =\", M_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945e81dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************  AVERAGE STATS  *********************\n",
      "Median:\t M_opt =  0.0 \t M_rand =  0.91\n"
     ]
    }
   ],
   "source": [
    "# *************** RESULTS FOR THE SAME PARAMETERS FROM DICTIONARY *************\n",
    "output_folder = os.path.join(os.getcwd(), 'results')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "fname = output_folder + '/Q17.pkl'\n",
    "with open(fname, 'rb') as handle:\n",
    "    stats_dict = pickle.load(handle)\n",
    "    \n",
    "# Best_n_star\n",
    "stats_dict_best_n_star = [stats_dict[i][10000.0] for i in range(4)]\n",
    "final_m_opt = [stats_dict_best_n_star[i][1] for i in range(4)]\n",
    "final_m_rand = [stats_dict_best_n_star[i][2] for i in range(4)]\n",
    "\n",
    "# Results\n",
    "print('*********************', ' AVERAGE STATS ', '*********************')\n",
    "print(\"Median:\\t M_opt = \", np.round(np.median(final_m_opt),decimals=2),\n",
    "      \"\\t M_rand = \", np.round(np.median(final_m_rand),decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2826d707",
   "metadata": {},
   "source": [
    "#### Question 19: Heatmaps of the Q-values in 3 significant states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Optimal params\n",
    "epsilon_min = 0.1\n",
    "epsilon_max = 0.8\n",
    "n_star = 10000\n",
    "epsilon_exploration_rule = return_lambda_explor(epsilon_min, epsilon_max, n_star)\n",
    "\n",
    "# Training\n",
    "model, stats = deep_q_learning(env, alpha=0.05, epsilon_exploration_rule=epsilon_exploration_rule, self_practice=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f8b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States of interest\n",
    "win_chance = [1., 0., 0., -1., 1., 0., 0., -1., 0.]\n",
    "block_win = [1., 0., 1., 0., -1., 0., 0., 0., 0.]\n",
    "fork_chance = [1., -1., 1., -1., 0., 0., 0., 0., 0.]\n",
    "grids = [win_chance, block_win, fork_chance]\n",
    "\n",
    "\n",
    "grid_numpy = []\n",
    "for i in range(len(grids)):\n",
    "    grid_numpy.append(np.array(grids[i]).reshape(3,3))\n",
    "    \n",
    "# Plot heatmaps\n",
    "heatmaps_deep_subplots(grid_numpy, model, save=save_figs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5faa8d",
   "metadata": {},
   "source": [
    "## 4. Comparison between Q-Learning and Deep Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fa259d",
   "metadata": {},
   "source": [
    "#### Question 20: Training times for both learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b74f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************  AVERAGE STATS  *********************\n",
      "Median:\t M_opt =  0.0 \t M_rand =  0.85 \t T_train =  6625.0\n",
      "25th quantile:\t M_opt =  0.0 \t M_rand =  0.82 \t T_train =  5812.5\n",
      "75th quantile:\t M_opt =  0.0 \t M_rand =  0.89 \t T_train =  7375.0\n"
     ]
    }
   ],
   "source": [
    "# Load results of best parameters from dictionary\n",
    "output_folder = os.path.join(os.getcwd(), 'results')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "fname = output_folder + '/Q4.pkl'\n",
    "with open(fname, 'rb') as handle:\n",
    "    stats_dict = pickle.load(handle)\n",
    "\n",
    "# Best_n_star\n",
    "stats_dict_best_n_star = [stats_dict[i][0.5] for i in range(10)]\n",
    "final_m_opt = [stats_dict_best_n_star[i][1] for i in range(10)]\n",
    "test_m_opt = [stats_dict_best_n_star[i][0]['test_Mopt'] for i in range(10)]\n",
    "final_m_rand = [stats_dict_best_n_star[i][2] for i in range(10)]\n",
    "test_m_rand = [stats_dict_best_n_star[i][0]['test_Mrand'] for i in range(10)]\n",
    "\n",
    "# Compute training time\n",
    "starting_m_opt = [test_m_opt[i][0] for i in range(10)]\n",
    "train_times_m_opt = np.array([np.where(np.array(test_m_opt[i]) > starting_m_opt[i] \n",
    "                                       + 0.8 * (final_m_opt[i]-starting_m_opt[i]))[0][0] for i in range(10)])\n",
    "train_times_m_opt = train_times_m_opt * test_freq\n",
    "train_times_m_opt\n",
    "starting_m_rand = [test_m_rand[i][0] for i in range(10)]\n",
    "train_times_m_rand = np.array([np.where(np.array(test_m_rand[i]) > starting_m_rand[i] \n",
    "                                       + 0.8 * (final_m_rand[i]-starting_m_rand[i]))[0][0] for i in range(10)])\n",
    "train_times_m_rand = train_times_m_rand * test_freq\n",
    "train_times = [np.maximum(train_times_m_opt[i], train_times_m_rand[i]) for i in range(10)]\n",
    "\n",
    "# Results\n",
    "print('*********************', ' AVERAGE STATS ', '*********************')\n",
    "print(\"Median:\\t M_opt = \", np.round(np.median(final_m_opt),decimals=2),\n",
    "      \"\\t M_rand = \", np.round(np.median(final_m_rand),decimals=2), \n",
    "      \"\\t T_train = \", np.round(np.median(train_times),decimals=2))\n",
    "print(\"25th quantile:\\t M_opt = \", np.round(np.percentile(final_m_opt, q=25),decimals=2), \n",
    "      \"\\t M_rand = \", np.round(np.percentile(final_m_rand, q=25),decimals=2), \n",
    "      \"\\t T_train = \", np.round(np.percentile(train_times, q=25),decimals=2))\n",
    "print(\"75th quantile:\\t M_opt = \", np.round(np.percentile(final_m_opt, q=75),decimals=2),\n",
    "      \"\\t M_rand = \", np.round(np.percentile(final_m_rand, q=75),decimals=2),\n",
    "      \"\\t T_train = \", np.round(np.percentile(train_times, q=75),decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "820b2ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************  AVERAGE STATS  *********************\n",
      "Median:\t M_opt =  -0.07 \t M_rand =  0.87 \t T_train =  6625.0\n",
      "25th quantile:\t M_opt =  -0.19 \t M_rand =  0.86 \t T_train =  5062.5\n",
      "75th quantile:\t M_opt =  0.0 \t M_rand =  0.9 \t T_train =  8812.5\n"
     ]
    }
   ],
   "source": [
    "# Load results of best parameters from dictionary\n",
    "output_folder = os.path.join(os.getcwd(), 'results')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "fname = output_folder + '/Q8.pkl'\n",
    "with open(fname, 'rb') as handle:\n",
    "    stats_dict = pickle.load(handle)\n",
    "\n",
    "# Best_n_star\n",
    "stats_dict_best_n_star = [stats_dict[i][24460.0] for i in range(10)]\n",
    "final_m_opt = [stats_dict_best_n_star[i][1] for i in range(10)]\n",
    "test_m_opt = [stats_dict_best_n_star[i][0]['test_Mopt'] for i in range(10)]\n",
    "final_m_rand = [stats_dict_best_n_star[i][2] for i in range(10)]\n",
    "test_m_rand = [stats_dict_best_n_star[i][0]['test_Mrand'] for i in range(10)]\n",
    "\n",
    "# Compute training time\n",
    "starting_m_opt = [test_m_opt[i][0] for i in range(10)]\n",
    "train_times_m_opt = np.array([np.where(np.array(test_m_opt[i]) > starting_m_opt[i] \n",
    "                                       + 0.8 * (final_m_opt[i]-starting_m_opt[i]))[0][0] for i in range(10)])\n",
    "train_times_m_opt = train_times_m_opt * test_freq\n",
    "train_times_m_opt\n",
    "starting_m_rand = [test_m_rand[i][0] for i in range(10)]\n",
    "train_times_m_rand = np.array([np.where(np.array(test_m_rand[i]) > starting_m_rand[i] \n",
    "                                       + 0.8 * (final_m_rand[i]-starting_m_rand[i]))[0][0] for i in range(10)])\n",
    "train_times_m_rand = train_times_m_rand * test_freq\n",
    "train_times = [np.maximum(train_times_m_opt[i], train_times_m_rand[i]) for i in range(10)]\n",
    "\n",
    "# Results\n",
    "print('*********************', ' AVERAGE STATS ', '*********************')\n",
    "print(\"Median:\\t M_opt = \", np.round(np.median(final_m_opt),decimals=2),\n",
    "      \"\\t M_rand = \", np.round(np.median(final_m_rand),decimals=2), \n",
    "      \"\\t T_train = \", np.round(np.median(train_times),decimals=2))\n",
    "print(\"25th quantile:\\t M_opt = \", np.round(np.percentile(final_m_opt, q=25),decimals=2), \n",
    "      \"\\t M_rand = \", np.round(np.percentile(final_m_rand, q=25),decimals=2), \n",
    "      \"\\t T_train = \", np.round(np.percentile(train_times, q=25),decimals=2))\n",
    "print(\"75th quantile:\\t M_opt = \", np.round(np.percentile(final_m_opt, q=75),decimals=2),\n",
    "      \"\\t M_rand = \", np.round(np.percentile(final_m_rand, q=75),decimals=2),\n",
    "      \"\\t T_train = \", np.round(np.percentile(train_times, q=75),decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ae7a708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************  AVERAGE STATS  *********************\n",
      "Median:\t M_opt =  0.0 \t M_rand =  0.94 \t T_train =  3500.0\n"
     ]
    }
   ],
   "source": [
    "# Load results of best parameters from dictionary\n",
    "output_folder = os.path.join(os.getcwd(), 'results')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "fname = output_folder + '/Q14.pkl'\n",
    "with open(fname, 'rb') as handle:\n",
    "    stats_dict = pickle.load(handle)\n",
    "    \n",
    "# Best_n_star\n",
    "stats_dict_best_n_star = [stats_dict[i][0.5] for i in range(4)]\n",
    "final_m_opt = [stats_dict_best_n_star[i][1] for i in range(4)]\n",
    "test_m_opt = [stats_dict_best_n_star[i][0]['test_Mopt'] for i in range(4)]\n",
    "final_m_rand = [stats_dict_best_n_star[i][2] for i in range(4)]\n",
    "test_m_rand = [stats_dict_best_n_star[i][0]['test_Mrand'] for i in range(4)]\n",
    "\n",
    "# Compute training time\n",
    "starting_m_opt = [test_m_opt[i][0] for i in range(4)]\n",
    "train_times_m_opt = np.array([np.where(np.array(test_m_opt[i]) > starting_m_opt[i] \n",
    "                                       + 0.8 * (final_m_opt[i]-starting_m_opt[i]))[0][0] for i in range(4)])\n",
    "train_times_m_opt = train_times_m_opt * test_freq\n",
    "train_times_m_opt\n",
    "starting_m_rand = [test_m_rand[i][0] for i in range(4)]\n",
    "train_times_m_rand = np.array([np.where(np.array(test_m_rand[i]) > starting_m_rand[i] \n",
    "                                       + 0.8 * (final_m_rand[i]-starting_m_rand[i]))[0][0] for i in range(4)])\n",
    "train_times_m_rand = train_times_m_rand * test_freq\n",
    "train_times = [np.maximum(train_times_m_opt[i], train_times_m_rand[i]) for i in range(4)]\n",
    "\n",
    "# Results\n",
    "print('*********************', ' AVERAGE STATS ', '*********************')\n",
    "print(\"Median:\\t M_opt = \", np.round(np.median(final_m_opt),decimals=2),\n",
    "      \"\\t M_rand = \", np.round(np.median(final_m_rand),decimals=2), \n",
    "      \"\\t T_train = \", np.round(np.median(train_times),decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c491728e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************  AVERAGE STATS  *********************\n",
      "Median:\t M_opt =  0.0 \t M_rand =  0.91 \t T_train =  4000.0\n"
     ]
    }
   ],
   "source": [
    "# Load results of best parameters from dictionary\n",
    "output_folder = os.path.join(os.getcwd(), 'results')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "fname = output_folder + '/Q17.pkl'\n",
    "with open(fname, 'rb') as handle:\n",
    "    stats_dict = pickle.load(handle)\n",
    "    \n",
    "# Best_n_star\n",
    "stats_dict_best_n_star = [stats_dict[i][10000.0] for i in range(4)]\n",
    "final_m_opt = [stats_dict_best_n_star[i][1] for i in range(4)]\n",
    "test_m_opt = [stats_dict_best_n_star[i][0]['test_Mopt'] for i in range(4)]\n",
    "final_m_rand = [stats_dict_best_n_star[i][2] for i in range(4)]\n",
    "test_m_rand = [stats_dict_best_n_star[i][0]['test_Mrand'] for i in range(4)]\n",
    "\n",
    "# Compute training time\n",
    "starting_m_opt = [test_m_opt[i][0] for i in range(4)]\n",
    "train_times_m_opt = np.array([np.where(np.array(test_m_opt[i]) > starting_m_opt[i] \n",
    "                                       + 0.8 * (final_m_opt[i]-starting_m_opt[i]))[0][0] for i in range(4)])\n",
    "train_times_m_opt = train_times_m_opt * test_freq\n",
    "train_times_m_opt\n",
    "starting_m_rand = [test_m_rand[i][0] for i in range(4)]\n",
    "train_times_m_rand = np.array([np.where(np.array(test_m_rand[i]) > starting_m_rand[i] \n",
    "                                       + 0.8 * (final_m_rand[i]-starting_m_rand[i]))[0][0] for i in range(4)])\n",
    "train_times_m_rand = train_times_m_rand * test_freq\n",
    "train_times = [np.maximum(train_times_m_opt[i], train_times_m_rand[i]) for i in range(4)]\n",
    "\n",
    "# Results\n",
    "print('*********************', ' AVERAGE STATS ', '*********************')\n",
    "print(\"Median:\\t M_opt = \", np.round(np.median(final_m_opt),decimals=2),\n",
    "      \"\\t M_rand = \", np.round(np.median(final_m_rand),decimals=2), \n",
    "      \"\\t T_train = \", np.round(np.median(train_times),decimals=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS456",
   "language": "python",
   "name": "cs456"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
